<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		 
			
  
    <meta name="twitter:card" content="summary"/>
    
      <meta name="twitter:image" content="https://blog.kissy.fr/images/avatar.png" />
    
  
  
  <meta name="twitter:title" content="Policy Evaluation on Frozen-Lake"/>
  <meta name="twitter:description" content="The Policy Evaluation algorithm compute iteratively the state-value function $v_\pi$
for a given policy $\pi$ for a known model in an MDP environment."/>
  
  
  
  
    <meta name="twitter:creator" content="@Guillaume Le Biller"/>
  



		
		<meta name="author" content="Guillaume Le Biller">
		<meta name="description" content="Any fool can know. The point is to understand.">
		<meta name="generator" content="Hugo 0.54.0" />
		<title>Policy Evaluation on Frozen-Lake &middot; Practical Thoughts</title>
		<link rel="shortcut icon" href="https://blog.kissy.fr/images/favicon.ico">

		
		<link rel="stylesheet" href="/css/bundle.min.css">

		
		
			<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

			
			<link rel="stylesheet" href="/posts/reinforcement-learning-algorithms/policy-evaluation/bundle.min.css">
		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='https://blog.kissy.fr/'> <span class="arrow">←</span>Home</a>
	
	<a href='https://blog.kissy.fr/posts'>Archive</a>
	<a href='https://blog.kissy.fr/tags'>Tags</a>
	<a href='https://blog.kissy.fr/about'>About</a>

	

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        Policy Evaluation on Frozen-Lake
                    </h1>
                    <h2 class="headline">
                    Mar 23, 2019
                    · 164 words
                    · 1 minute read
                      <span class="tags">
                      
                      </span>
                    </h2>
                </header>
                
                <section id="post-body">
                    <p>The Policy Evaluation algorithm compute iteratively the state-value function $v_\pi$
for a given policy $\pi$ for a known model in an MDP environment.</p>

<h1 id="iterative-algorithm">Iterative algorithm</h1>

<p>A complete in-place version of iterative policy evaluation is shown in pseudocode in
the box below. <sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup></p>

<div class="algorithm">
    <p><b>Input:</b></p>
    <p class="i1">a policy $\pi$ to be evaluated</p>
    <p><b>Parameter:</b></p>
    <p class="i1">a small threshold $\theta > 0$ determining accuracy of estimation</p>
    <br />
    <p><b>Initialization:</b></p>
    <p class="i1">$V(s) \text{, for all } S \in S^+$, arbitrarily except that $V(terminal) = 0$</p>
    <p><b>Policy Evaluation:</b></p>
    <p class="i1">$\nabla \leftarrow 0$</p>
    <p class="i1">Loop for each $s \in S$:</p>
    <p class="i2">$v \leftarrow V(s)$</p>
    <p class="i2">$V(s) \leftarrow \sum_a \pi(a|s) \sum_{s',r} p(s',r|s,a)[r + \gamma V(s')]$</p>
    <p class="i2">$\nabla \leftarrow max(\nabla, |v - V(s)|)$</p>
    <p>Until $\nabla < 0$</p>
</div>

<h1 id="frozen-lake-https-gym-openai-com-envs-frozenlake-v0-implementation"><a href="https://gym.openai.com/envs/FrozenLake-v0/">Frozen Lake</a> implementation</h1>

<p>The implementation of the Policy Evaluation algorithm on the Frozen Lake problem
displaying the value function $V(s)$ at each time step $t$ for different input policies:</p>

<ul>
<li>Optimal Policy — $v_*$</li>
<li>Policy with equal probability</li>
<li>Random policy</li>
</ul>

<div class="policy-evaluation-frozen-lake"></div>

<div style="text-align: right">
<a href="https://blog.kissy.fr/posts/reinforcement-learning-algorithms/">Table of content</a>
</div>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">Sutton, R. S., &amp; Barto, A. G. (2018). <a href="http://www.incompleteideas.net/book/RLbook2018.pdf">4.1 Policy Evaluation</a>. In Reinforcement learning: an introduction.
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
</ol>
</div>
                </section>
            </article>

            

            

            

            <footer id="footer">
    
        <div id="social">
    
    <a class="symbol" href="https://www.github.com/Kissy" target="_blank">
        <img src="https://blog.kissy.fr/images/github-icon.svg" />
    </a>
    
    <a class="symbol" href="https://www.linkedin.com/in/guillaume-le-biller-b1b38773/" target="_blank">
        <img src="https://blog.kissy.fr/images/linkedin-icon.svg" />
    </a>
    
</div>

    
    <p class="small">
    
       © Copyright 2019 | Guillaume Le Biller
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        
<script type="text/javascript">"document.addEventListener(\"DOMContentLoaded\",function(){if(window.devicePixelRatio!==2){return;}\nvar images=document.querySelectorAll(\"img[data-2x]\");Array.prototype.forEach.call(images,function(el,i){var src=el.getAttribute(\"data-2x\");el.setAttribute(\"src\",src);});});"</script>



  <script type="text/javascript" defer src="https://cdnjs.cloudflare.com/ajax/libs/d3/5.9.2/d3.min.js"></script>
  
  <script type="text/javascript" defer src="/posts/reinforcement-learning-algorithms/policy-evaluation/bundle.min.js"></script>


<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        TeX: { equationNumbers: { autoNumber: "AMS" },
            extensions: ["AMSmath.js", "AMSsymbols.js"] }
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

<script type="text/javascript" defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js">
    hljs.initHighlightingOnLoad();
</script>


  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-4258818-9', 'auto');
	
	ga('send', 'pageview');
}
</script>




    </body>
</html>
